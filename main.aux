\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{ecta}
\citation{Barberis2013}
\citation{Barberis2013}
\citation{TverskyKahneman1992}
\citation{Peters2019b}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction and outline}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Consistent probability weighting as a difference between models}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Probabilities are tricky}{2}{subsection.2.1}}
\citation{Peters2019b}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces This table assumes $T=$10,000 observed time intervals. To be read as follows (first line): for an event of true probability 0.5, the most likely count in 10,000 trials is 5,000. Assuming Poissonian statistics, this comes with an estimation error of $\sqrt  {5,000}/10,000=0.01$, which is 2\% of the true probability.\relax }}{3}{table.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:errors}{{1}{3}{This table assumes $T=$10,000 observed time intervals. To be read as follows (first line): for an event of true probability 0.5, the most likely count in 10,000 trials is 5,000. Assuming Poissonian statistics, this comes with an estimation error of $\sqrt {5,000}/10,000=0.01$, which is 2\% of the true probability.\relax }{table.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Disinterested observers and decision makers have different incentives}{3}{subsection.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}The Gaussian case}{4}{section.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Probability density function (blue), estimated by a DO; and decision-weight density function (red), estimated by a DM. The DO models returns with a best estimate for the variance and assumes the true frequency distribution is the blue line. The DM wants to be on the safe side, models returns with a greater variance, and assumes the true frequency distribution is the red line. The DM appears to the DO as someone who over-estimates probabilities of low-probability events and underestimates probabilities of high-probability events.\relax }}{5}{figure.caption.2}}
\newlabel{fig:probability_dists}{{1}{5}{Probability density function (blue), estimated by a DO; and decision-weight density function (red), estimated by a DM. The DO models returns with a best estimate for the variance and assumes the true frequency distribution is the blue line. The DM wants to be on the safe side, models returns with a greater variance, and assumes the true frequency distribution is the red line. The DM appears to the DO as someone who over-estimates probabilities of low-probability events and underestimates probabilities of high-probability events.\relax }{figure.caption.2}{}}
\newlabel{eq:q}{{3.1}{5}{The Gaussian case}{equation.3.1}{}}
\newlabel{eq:p}{{3.2}{5}{The Gaussian case}{equation.3.2}{}}
\newlabel{eq:q_of_p}{{3.3}{5}{The Gaussian case}{equation.3.3}{}}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Decision weight density (used by a DM) vs. probability density (used by a DO) for the Gaussian model (blue), compared to the diagonal (black) where DM and DO use the same parameters. For low probabilities, the decision weights are higher than the probabilities; for high probabilities they are lower.\relax }}{6}{figure.caption.3}}
\newlabel{fig:probability_weights}{{2}{6}{Decision weight density (used by a DM) vs. probability density (used by a DO) for the Gaussian model (blue), compared to the diagonal (black) where DM and DO use the same parameters. For low probabilities, the decision weights are higher than the probabilities; for high probabilities they are lower.\relax }{figure.caption.3}{}}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces CDF as assumed by the DO (red) and by the DM (blue), Gaussian distributions, where the DO assumes scale 1 and the DM cautiously assumes scale 2. Following the dashed vertical lines (left to right), we see that for small values of the CDF the DM's is larger than the DO's; the curves coincide at 0.5 because no difference in location is assumed; and for large values of the CDF the DM's is smaller than the DO's \relax }}{7}{figure.caption.4}}
\newlabel{fig:decision_map}{{3}{7}{CDF as assumed by the DO (red) and by the DM (blue), Gaussian distributions, where the DO assumes scale 1 and the DM cautiously assumes scale 2. Following the dashed vertical lines (left to right), we see that for small values of the CDF the DM's is larger than the DO's; the curves coincide at 0.5 because no difference in location is assumed; and for large values of the CDF the DM's is smaller than the DO's \relax }{figure.caption.4}{}}
\newlabel{eq:correspondence}{{3.4}{7}{The Gaussian case}{equation.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Other probability distributions}{7}{section.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Decision weight CDFs used by a DM vs. probability CDFs used by a DO.  Top left) Gaussian distribution, difference in scale. DO assumes location 0, scale 1; DM assumes location 0, scale 2.7 (broader than DO).  Top right) Gaussian distribution, difference in location. DO assumes location 0, scale 1; DM assumes location 0.18 (bigger than DO), scale 1. Bottom left) Gaussian distribution, differences in scale and location. DO assumes location 0, scale 1; DM assumes location 0.18 (bigger than DO), scale 2.7 (broader than DO).  Bottom right) Fit to observations reported by \citet  {TverskyKahneman1992}. This is Eq.\nobreakspace  {}(\ref  {eq:correspondence}) with $\alpha =0.65$. The observations by \citet  {TverskyKahneman1992} are consistent with a DM assuming a scale and location in real-world decisions that differ from those assumed by the DO.\relax }}{8}{figure.caption.5}}
\newlabel{fig:CDF_weights}{{4}{8}{Decision weight CDFs used by a DM vs. probability CDFs used by a DO.\\ Top left) Gaussian distribution, difference in scale. DO assumes location 0, scale 1; DM assumes location 0, scale 2.7 (broader than DO).\\ Top right) Gaussian distribution, difference in location. DO assumes location 0, scale 1; DM assumes location 0.18 (bigger than DO), scale 1. Bottom left) Gaussian distribution, differences in scale and location. DO assumes location 0, scale 1; DM assumes location 0.18 (bigger than DO), scale 2.7 (broader than DO).\\ Bottom right) Fit to observations reported by \citet {TverskyKahneman1992}. This is \eref {correspondence} with $\alpha =0.65$. The observations by \citet {TverskyKahneman1992} are consistent with a DM assuming a scale and location in real-world decisions that differ from those assumed by the DO.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Probability weighting for Student-t distributions, where the DM uses a different shape parameter (1) and a different location parameter (0) from those of the DO (2 and 0.2, respectively).\relax }}{9}{figure.caption.6}}
\newlabel{fig:other_CDFs}{{5}{9}{Probability weighting for Student-t distributions, where the DM uses a different shape parameter (1) and a different location parameter (0) from those of the DO (2 and 0.2, respectively).\relax }{figure.caption.6}{}}
\bibdata{./../LML_bibliography/bibliography}
\bibcite{Barberis2013}{{1}{2013}{{Barberis}}{{Barberis}}}
\bibcite{Peters2019b}{{2}{2019}{{Peters}}{{Peters}}}
\bibcite{TverskyKahneman1992}{{3}{1992}{{Tversky and Kahneman}}{{Tversky and Kahneman}}}
