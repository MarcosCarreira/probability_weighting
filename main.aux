\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces {\bf  Empirical phenomenon of probability weighting.} Cumulative decision weights $F_w$ (used by decision makers) versus cumulative probabilities $F_p$ (used by disinterested observers), as reported by \citet  [p.\nobreakspace  {}310, Fig. 1, relabelled axes]{TverskyKahneman1992}. The figure is to be read as follows: pick a point along the horizontal axis (the cumulative probability $F_p$ used by a DO) and look up the corresponding value on the vertical axis of the dotted inverse-S curve (the cumulative decision weight $F_w$ used by a DM). Low cumulative probabilities (left) are exceeded by their corresponding cumulative decision weights, and for high cumulative probabilities it's the other way around. It's the inverse-S shape of the curve that indicates this qualitative relationship.\relax }}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:TK1992}{{1}{3}{{\bf Empirical phenomenon of probability weighting.} Cumulative decision weights $F_w$ (used by decision makers) versus cumulative probabilities $F_p$ (used by disinterested observers), as reported by \citet [p.~310, Fig. 1, relabelled axes]{TverskyKahneman1992}. The figure is to be read as follows: pick a point along the horizontal axis (the cumulative probability $F_p$ used by a DO) and look up the corresponding value on the vertical axis of the dotted inverse-S curve (the cumulative decision weight $F_w$ used by a DM). Low cumulative probabilities (left) are exceeded by their corresponding cumulative decision weights, and for high cumulative probabilities it's the other way around. It's the inverse-S shape of the curve that indicates this qualitative relationship.\relax }{figure.caption.1}{}}
\newlabel{eq:SN}{{3}{3}{Introduction}{equation.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Probability weighting as a difference between models}{3}{section.2}\protected@file@percent }
\newlabel{sec:ModelDiff}{{2}{3}{Probability weighting as a difference between models}{section.2}{}}
\citation{TverskyKahneman1992}
\newlabel{sec:The_inverse}{{2.1}{4}{The inverse-S curve\seclabel {The_inverse}}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The inverse-S curve}{4}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Tversky and Kahneman}{4}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{eq:correspondence}{{4}{4}{Tversky and Kahneman}{equation.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Scale, location, and the inverse-S}{4}{subsubsection.2.1.2}\protected@file@percent }
\newlabel{eq:DecisionW}{{5}{4}{Scale, location, and the inverse-S}{equation.2.5}{}}
\newlabel{eq:p}{{6}{4}{Scale, location, and the inverse-S}{equation.2.6}{}}
\newlabel{eq:w_of_p}{{7}{4}{Scale, location, and the inverse-S}{equation.2.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces {\bf  Mapping PDFs.} Left: probability PDF (red), estimated by a DO; and decision-weight PDF (blue), estimated by a DM. The DO models $x$ with a best estimate for the scale (standard deviation) and assumes the true frequency distribution is the red line. The DM models $x$ with a greater scale (here 2 times greater, $\alpha =2$), and assumes the true frequency distribution is the blue line. Comparing the two curves, the DM appears to the DO as someone who over-estimates probabilities of low-probability events and underestimates probabilities of high-probability events, indicated by vertical arrows. Right: the difference between decision weights and probabilities can also be expressed by directly plotting, for any value of $x$, the decision weight {\it  vs.} the probability observed at $x$. This corresponds to a non-linear distortion of the horizontal axis. The arrows on the left correspond to the same $x$-values as on the right. They therefore start and end at identical vertical positions as on the left. Because of the non-linear distortion of the horizontal axis, they are shifted to different locations horizontally.\relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig:probability_dists}{{2}{5}{{\bf Mapping PDFs.} Left: probability PDF (red), estimated by a DO; and decision-weight PDF (blue), estimated by a DM. The DO models $x$ with a best estimate for the scale (standard deviation) and assumes the true frequency distribution is the red line. The DM models $x$ with a greater scale (here 2 times greater, $\alpha =2$), and assumes the true frequency distribution is the blue line. Comparing the two curves, the DM appears to the DO as someone who over-estimates probabilities of low-probability events and underestimates probabilities of high-probability events, indicated by vertical arrows. Right: the difference between decision weights and probabilities can also be expressed by directly plotting, for any value of $x$, the decision weight {\it vs.} the probability observed at $x$. This corresponds to a non-linear distortion of the horizontal axis. The arrows on the left correspond to the same $x$-values as on the right. They therefore start and end at identical vertical positions as on the left. Because of the non-linear distortion of the horizontal axis, they are shifted to different locations horizontally.\relax }{figure.caption.2}{}}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces {\bf  Mapping CDFs.} Left: The DO assumes the observable $X$ follows Gaussian distribution $X \sim \mathcal  {N}(0,1)$, which results in the red CDF of the standard normal, $F_p(x) = \Phi _{0,1}(x)$. The DM is more cautious, in his model the same observable $X$ follows a wider Gaussian distribution, $X \sim \mathcal  {N}(0,3)$ depicted by $F_w(x)$ (blue). Following the vertical arrows (left to right), we see that for low values of the event probability $x$ the DM's CDF is larger than the DO's CDF, $F_p(x) < F_w(x)$; the curves coincide at 0.5 because no difference in location is assumed; necessarily for large values of the event probability $x$ the DM's CDF must be lower than the DO's. Right: the same CDFs as on the left but now plotted not against $x$ but against the CDF $F_p$. Trivially, the CDF $F_p$ plotted against itself is the diagonal; the CDF $F_w$ now displays the generic inverse-S shape known from prospect theory. The arrows start and end at the same vertical values as on the left. Because the horizontal axis is has been non-linearly stretched (as the argument changed from $x$ to $F_p$), their horizontal locations are shifted. \relax }}{6}{figure.caption.3}\protected@file@percent }
\newlabel{fig:TwoCDFs}{{3}{6}{{\bf Mapping CDFs.} Left: The DO assumes the observable $X$ follows Gaussian distribution $X \sim \ND (0,1)$, which results in the red CDF of the standard normal, $F_p(x) = \Phi _{0,1}(x)$. The DM is more cautious, in his model the same observable $X$ follows a wider Gaussian distribution, $X \sim \ND (0,3)$ depicted by $F_w(x)$ (blue). Following the vertical arrows (left to right), we see that for low values of the event probability $x$ the DM's CDF is larger than the DO's CDF, $F_p(x) < F_w(x)$; the curves coincide at 0.5 because no difference in location is assumed; necessarily for large values of the event probability $x$ the DM's CDF must be lower than the DO's. Right: the same CDFs as on the left but now plotted not against $x$ but against the CDF $F_p$. Trivially, the CDF $F_p$ plotted against itself is the diagonal; the CDF $F_w$ now displays the generic inverse-S shape known from prospect theory. The arrows start and end at the same vertical values as on the left. Because the horizontal axis is has been non-linearly stretched (as the argument changed from $x$ to $F_p$), their horizontal locations are shifted. \relax }{figure.caption.3}{}}
\newlabel{sec:A_mismatch}{{2.2}{6}{Different scales and locations\seclabel {A_mismatch}}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Different scales and locations}{6}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces {\bf  CDF maps, Gaussian distribution}.  Top left: Difference in scale. DO assumes location 0, scale 1; DM assumes location 0, scale 1.64 (broader than DO).  Top right: Difference in location. DO assumes location 0, scale 1; DM assumes location 0.18 (bigger than DO), scale 1.  Bottom left: Differences in scale and location. DO assumes location 0, scale 1; DM assumes location 0.18 (bigger than DO), scale 1.64 (broader than DO).  Bottom right: Fit to observations reported by \cite  {TverskyKahneman1992}. This is (Eq.\nobreakspace  {}\ref  {eq:correspondence}) with $\gamma =0.65$. Note the similarity to bottom left.\relax }}{7}{figure.caption.4}\protected@file@percent }
\newlabel{fig:CDF_weights}{{4}{7}{{\bf CDF maps, Gaussian distribution}.\\ Top left: Difference in scale. DO assumes location 0, scale 1; DM assumes location 0, scale 1.64 (broader than DO).\\ Top right: Difference in location. DO assumes location 0, scale 1; DM assumes location 0.18 (bigger than DO), scale 1.\\ Bottom left: Differences in scale and location. DO assumes location 0, scale 1; DM assumes location 0.18 (bigger than DO), scale 1.64 (broader than DO).\\ Bottom right: Fit to observations reported by \cite {TverskyKahneman1992}. This is \eref {correspondence} with $\gamma =0.65$. Note the similarity to bottom left.\relax }{figure.caption.4}{}}
\newlabel{sec:Different_shapes}{{2.3}{8}{Different shapes\seclabel {Different_shapes}}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Different shapes}{8}{subsection.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Probability weighting for $t$-distributions, where the DM uses a different shape parameter (1) and a different location parameter (0) from those of the DO (2 and 0.2, respectively).\relax }}{8}{figure.caption.5}\protected@file@percent }
\newlabel{fig:fat_tailed_CDF}{{5}{8}{Probability weighting for $t$-distributions, where the DM uses a different shape parameter (1) and a different location parameter (0) from those of the DO (2 and 0.2, respectively).\relax }{figure.caption.5}{}}
\newlabel{sec:Reasons_for}{{3}{9}{Reasons for different models\seclabel {Reasons_for}}{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Reasons for different models}{9}{section.3}\protected@file@percent }
\newlabel{sec:tricky}{{3.1}{9}{Some meanings of ``probability'' \seclabel {tricky}}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Some meanings of ``probability'' }{9}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Frequency-in-an-ensemble interpretation of probability}{9}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Frequency-over-time interpretation of probability}{9}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Degree-of-belief interpretation of probability}{9}{section*.8}\protected@file@percent }
\newlabel{sec:condition2}{{3.2}{10}{Consistent differences between DO and DM \seclabel {condition2}}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Consistent differences between DO and DM }{10}{subsection.3.2}\protected@file@percent }
\newlabel{eq:count_est}{{10}{10}{Estimation errors for probabilities}{equation.3.10}{}}
\newlabel{eq:prob_est}{{11}{11}{Estimation errors for probabilities}{equation.3.11}{}}
\newlabel{eq:weight_density}{{13}{11}{Estimation errors for probabilities}{equation.3.13}{}}
\citation{Peters2019b}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces PDFs (left) and inverse-S curves (right) arising when the DO assumes a Gaussian (scale 1, location 0, top line) or a $t$-distribution (shape 2, location 0, bottom line), and the DM uses decision weights according to (Eq.\nobreakspace  {}\ref  {eq:weight_density}) with $T\delta x=10$. For the fat-tailed $t$-distribution (in the bottom line) the difference between $p(x)$ and $w(x)$ is more pronounced.\relax }}{12}{figure.caption.10}\protected@file@percent }
\newlabel{fig:square_root_error}{{6}{12}{PDFs (left) and inverse-S curves (right) arising when the DO assumes a Gaussian (scale 1, location 0, top line) or a $t$-distribution (shape 2, location 0, bottom line), and the DM uses decision weights according to \eref {weight_density} with $T\delta x=10$. For the fat-tailed $t$-distribution (in the bottom line) the difference between $p(x)$ and $w(x)$ is more pronounced.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Typical situations of DO and DM: ergodicity}{12}{subsubsection.3.2.1}\protected@file@percent }
\citation{TverskyKahneman1992}
\citation{TverskyFox1995}
\citation{LattimoreBakerWitte1992}
\citation{tversky1995risk}
\citation{Prelec1998}
\newlabel{sec:Fitting_the}{{4}{13}{Fitting the model to experimental results \seclabel {Fitting_the}}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Fitting the model to experimental results }{13}{section.4}\protected@file@percent }
\newlabel{eq:LattimoreFunction}{{15}{13}{Fitting the model to experimental results \seclabel {Fitting_the}}{equation.4.15}{}}
\citation{TverskyKahneman1992}
\citation{TverskyFox1995}
\citation{LattimoreBakerWitte1992}
\citation{TverskyKahneman1992}
\citation{LattimoreBakerWitte1992}
\citation{TverskyKahneman1992}
\citation{Levenberg1944}
\citation{TverskyKahneman1992}
\citation{TverskyFox1995}
\citation{LattimoreBakerWitte1992}
\citation{TverskyKahneman1992}
\citation{LattimoreBakerWitte1992}
\citation{TverskyKahneman1992}
\citation{Levenberg1944}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Model fitting to experimental data from \cite  {TverskyKahneman1992} (left) and \cite  {TverskyFox1995} (right). Left: \cite  {LattimoreBakerWitte1992} (Eq.\nobreakspace  {}\ref  {eq:LattimoreFunction}): $\delta =0.67\tmspace  +\thinmuskip {.1667em}\left (SE = 0.04\right )$, $\gamma =0.58\tmspace  +\thinmuskip {.1667em}\left (\pm 0.03\right )$; Gaussian model: $\mu =0.38\tmspace  +\thinmuskip {.1667em}\left (\pm 0.06\right )$, $\sigma =1.60\tmspace  +\thinmuskip {.1667em}\left (\pm 0.10\right )$; $t$-model: $\nu =1.27\tmspace  +\thinmuskip {.1667em}\left (\pm 0.28\right )$, $\mu =0.40\tmspace  +\thinmuskip {.1667em}\left (\pm 0.07\right )$; \cite  {TverskyKahneman1992} (Eq.\nobreakspace  {}\ref  {eq:correspondence}): $\gamma =0.60\tmspace  +\thinmuskip {.1667em}\left (\pm 0.02\right )$. Right: \cite  {LattimoreBakerWitte1992}: $\delta =0.77\tmspace  +\thinmuskip {.1667em}\left (\pm 0.01\right )$, $\gamma =0.69\tmspace  +\thinmuskip {.1667em}\left (\pm 0.01\right )$; Gaussian model: $\mu =0.22\tmspace  +\thinmuskip {.1667em}\left (\pm 0.01\right )$, $\sigma =1.41\tmspace  +\thinmuskip {.1667em}\left (\pm 0.03\right )$; $t$-model: $\nu =1.41\tmspace  +\thinmuskip {.1667em}\left (\pm 0.21\right )$, $\mu =0.22\tmspace  +\thinmuskip {.1667em}\left (\pm 0.03\right )$; \cite  {TverskyKahneman1992}: $\gamma =0.68\tmspace  +\thinmuskip {.1667em}\left (\pm 0.01\right )$. Shaded areas indicate two standard errors in the fitted parameter values. The fit was done by implementing the Levenberg-Marquardt algorithm \cite  {Levenberg1944} for non-linear least squares curve fitting. \relax }}{14}{figure.caption.11}\protected@file@percent }
\newlabel{fig:TK_TF_fit}{{7}{14}{Model fitting to experimental data from \cite {TverskyKahneman1992} (left) and \cite {TverskyFox1995} (right). Left: \cite {LattimoreBakerWitte1992} \eref {LattimoreFunction}: $\delta =0.67\,\left (SE = 0.04\right )$, $\gamma =0.58\,\left (\pm 0.03\right )$; Gaussian model: $\mu =0.38\,\left (\pm 0.06\right )$, $\sigma =1.60\,\left (\pm 0.10\right )$; $t$-model: $\nu =1.27\,\left (\pm 0.28\right )$, $\mu =0.40\,\left (\pm 0.07\right )$; \cite {TverskyKahneman1992} \eref {correspondence}: $\gamma =0.60\,\left (\pm 0.02\right )$. Right: \cite {LattimoreBakerWitte1992}: $\delta =0.77\,\left (\pm 0.01\right )$, $\gamma =0.69\,\left (\pm 0.01\right )$; Gaussian model: $\mu =0.22\,\left (\pm 0.01\right )$, $\sigma =1.41\,\left (\pm 0.03\right )$; $t$-model: $\nu =1.41\,\left (\pm 0.21\right )$, $\mu =0.22\,\left (\pm 0.03\right )$; \cite {TverskyKahneman1992}: $\gamma =0.68\,\left (\pm 0.01\right )$. Shaded areas indicate two standard errors in the fitted parameter values. The fit was done by implementing the Levenberg-Marquardt algorithm \cite {Levenberg1944} for non-linear least squares curve fitting. \relax }{figure.caption.11}{}}
\citation{Sunstein2020}
\bibstyle{apalike}
\bibdata{../LML_bibliography/bibliography}
\bibcite{LattimoreBakerWitte1992}{{1}{1992}{{Lattimore et~al.}}{{}}}
\bibcite{Levenberg1944}{{2}{1944}{{Levenberg}}{{}}}
\bibcite{Peters2019b}{{3}{2019}{{Peters}}{{}}}
\bibcite{Prelec1998}{{4}{1998}{{Prelec}}{{}}}
\bibcite{Sunstein2020}{{5}{2020}{{Sunstein}}{{}}}
\bibcite{TverskyFox1995}{{6}{1995}{{Tversky and Fox}}{{}}}
\bibcite{TverskyKahneman1992}{{7}{1992}{{Tversky and Kahneman}}{{}}}
\bibcite{tversky1995risk}{{8}{1995}{{Tversky and Wakker}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{15}{section.5}\protected@file@percent }
