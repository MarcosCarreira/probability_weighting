\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{TverskyKahneman1992}
\citation{Barberis2013}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction and key observation}{1}{section.1}}
\@writefile{toc}{\contentsline {paragraph}{Organisation of the paper}{1}{section*.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Nomenclature}{1}{section.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces {\bf  Empirical phenomenon of probability weighting.} Cumulative decision weights $F_w$ (used by decision makers) versus cumulative probabilities $F_p$ (used by disinterested observers), as reported by \cite  [p. 310, Fig. 1]{TverskyKahneman1992}. The figure is to be read as follows: pick a point along the horizontal axis (the probability used by a DO) and look up the corresponding value on the vertical axis of the dotted inverse-S curve (the decision weight used by a DM). For low (cumulative) probabilities (left) the decision weight exceeds the probability, and for high probabilities it's the other way around. It's the inverse-S shape of the curve that indicates this qualitative relationship.\relax }}{2}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:TK1992}{{1}{2}{{\bf Empirical phenomenon of probability weighting.} Cumulative decision weights $F_w$ (used by decision makers) versus cumulative probabilities $F_p$ (used by disinterested observers), as reported by \cite [p. 310, Fig. 1]{TverskyKahneman1992}. The figure is to be read as follows: pick a point along the horizontal axis (the probability used by a DO) and look up the corresponding value on the vertical axis of the dotted inverse-S curve (the decision weight used by a DM). For low (cumulative) probabilities (left) the decision weight exceeds the probability, and for high probabilities it's the other way around. It's the inverse-S shape of the curve that indicates this qualitative relationship.\relax }{figure.caption.2}{}}
\newlabel{eq:SN}{{3}{2}{Nomenclature}{equation.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Consistent probability weighting as a difference between models}{2}{section.3}}
\newlabel{sec:ModelDiff}{{3}{2}{Consistent probability weighting as a difference between models}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Generic case: the Gaussian example}{3}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces {\bf  Two PDFs.} Probability density function (blue), estimated by a DO; and decision-weight density function (red), estimated by a DM. The DO models returns with a best estimate for the variance and assumes the true frequency distribution is the blue line. The DM wants to be on the safe side, models returns with a greater variance, and assumes the true frequency distribution is the red line. The DM appears to the DO as someone who over-estimates probabilities of low-probability events and underestimates probabilities of high-probability events.\relax }}{3}{figure.caption.3}}
\newlabel{fig:probability_dists}{{2}{3}{{\bf Two PDFs.} Probability density function (blue), estimated by a DO; and decision-weight density function (red), estimated by a DM. The DO models returns with a best estimate for the variance and assumes the true frequency distribution is the blue line. The DM wants to be on the safe side, models returns with a greater variance, and assumes the true frequency distribution is the red line. The DM appears to the DO as someone who over-estimates probabilities of low-probability events and underestimates probabilities of high-probability events.\relax }{figure.caption.3}{}}
\newlabel{eq:DecisionW}{{4}{4}{Generic case: the Gaussian example}{equation.3.4}{}}
\newlabel{eq:p}{{5}{4}{Generic case: the Gaussian example}{equation.3.5}{}}
\newlabel{eq:w_of_p}{{6}{4}{Generic case: the Gaussian example}{equation.3.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Decision weight density (used by a DM) vs. probability density (used by a DO) for the Gaussian model (blue), compared to the diagonal (black dashed) where DM and DO use the same parameters. For low probabilities, the decision weights are higher than the probabilities; for high probabilities they are lower.\relax }}{4}{figure.caption.4}}
\newlabel{fig:probability_weights}{{3}{4}{Decision weight density (used by a DM) vs. probability density (used by a DO) for the Gaussian model (blue), compared to the diagonal (black dashed) where DM and DO use the same parameters. For low probabilities, the decision weights are higher than the probabilities; for high probabilities they are lower.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces {\bf  Two Gaussian CDFs.} The DO assumes the observable $X$ follows Gaussian distribution $X \sim \mathcal  {N}(0,1)$, which results in the red CDF of the standard normal, $F_p(x) = \Phi _{0,1}(x)$. The DM is more cautious, in his model the same observable $X$ follows a wider Gaussian distribution with identical location, {\it  i.e.}\ a Gaussian with larger scale, $X \sim \mathcal  {N}(0,3)$ depicted by $F_w$ (blue). Following the dashed vertical lines (left to right), we see that for low values of the event probability $x$ the DM's CDF is larger than the DO's CDF, $F_p(x) < F_w(x)$; the curves coincide at 0.5 because no difference in location is assumed; necessarily for large values of the event probability $x$ the DM's CDF must be lower than the DO's.\relax }}{5}{figure.caption.5}}
\newlabel{fig:TwoCDFs}{{4}{5}{{\bf Two Gaussian CDFs.} The DO assumes the observable $X$ follows Gaussian distribution $X \sim \ND (0,1)$, which results in the red CDF of the standard normal, $F_p(x) = \Phi _{0,1}(x)$. The DM is more cautious, in his model the same observable $X$ follows a wider Gaussian distribution with identical location, \ie a Gaussian with larger scale, $X \sim \ND (0,3)$ depicted by $F_w$ (blue). Following the dashed vertical lines (left to right), we see that for low values of the event probability $x$ the DM's CDF is larger than the DO's CDF, $F_p(x) < F_w(x)$; the curves coincide at 0.5 because no difference in location is assumed; necessarily for large values of the event probability $x$ the DM's CDF must be lower than the DO's.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Lack of conceptual clarity about whose probabilities are analysed?}{6}{subsection.3.2}}
\newlabel{sec:tricky}{{3.2}{6}{Lack of conceptual clarity about whose probabilities are analysed?}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Frequency-in-an-ensemble interpretation of probability}{6}{section*.6}}
\@writefile{toc}{\contentsline {paragraph}{Frequency-over-time interpretation of probability}{6}{section*.7}}
\@writefile{toc}{\contentsline {paragraph}{Degree-of-belief interpretation of probability}{6}{section*.8}}
\citation{Peters2019b}
\citation{PetersAdamou2015a}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces This table assumes $T = 10000$ observed time intervals. To be read as follows (first line): for an event of true probability 0.5, the most likely count in 10000 trials is 5000. Assuming Poisson statistics, this comes with an estimation error of $\sqrt  {5000}/5000=0.01$, which is 2\% of the true probability.\relax }}{7}{table.caption.10}}
\newlabel{tab:errors}{{1}{7}{This table assumes $T = 10000$ observed time intervals. To be read as follows (first line): for an event of true probability 0.5, the most likely count in 10000 trials is 5000. Assuming Poisson statistics, this comes with an estimation error of $\sqrt {5000}/5000=0.01$, which is 2\% of the true probability.\relax }{table.caption.10}{}}
\newlabel{sec:condition2}{{3.3}{7}{Disinterested observers and decision makes have different perspectives \seclabel {condition2}}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Disinterested observers and decision makes have different perspectives }{7}{subsection.3.3}}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\citation{Barberis2013}
\citation{WuGonzalez1996,Prelec1998,GonzalezWu1999,Stott2006,DeGiorgi2006,Wakker2010,AbdellaouiETAL2011}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\citation{TverskyKahneman1992}
\newlabel{eq:correspondence}{{8}{8}{Disinterested observers and decision makes have different perspectives \seclabel {condition2}}{equation.3.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Other probability distributions}{8}{section.4}}
\newlabel{fig:subfig:GaussLocation}{{5a}{9}{Gaussian distribution, difference in scale. DO assumes location 0, scale 1; DM assumes location 0, scale 2.7 (broader than DO).\flabel {subfig:GaussLocation}\relax }{figure.caption.11}{}}
\newlabel{sub@fig:subfig:GaussLocation}{{a}{9}{Gaussian distribution, difference in scale. DO assumes location 0, scale 1; DM assumes location 0, scale 2.7 (broader than DO).\flabel {subfig:GaussLocation}\relax }{figure.caption.11}{}}
\newlabel{fig:subfig:GaussScale}{{5b}{9}{Gaussian distribution, difference in location. DO assumes location 0, scale 1; DM assumes location 0.18 (bigger than DO), scale 1.\flabel {subfig:GaussScale}\relax }{figure.caption.11}{}}
\newlabel{sub@fig:subfig:GaussScale}{{b}{9}{Gaussian distribution, difference in location. DO assumes location 0, scale 1; DM assumes location 0.18 (bigger than DO), scale 1.\flabel {subfig:GaussScale}\relax }{figure.caption.11}{}}
\newlabel{fig:subfig:GaussLocScale}{{5c}{9}{Gaussian distribution, differences in scale and location. DO assumes location 0, scale 1; DM assumes location 0.18 (bigger than DO), scale 2.7 (broader than DO).\flabel {subfig:GaussLocScale}\relax }{figure.caption.11}{}}
\newlabel{sub@fig:subfig:GaussLocScale}{{c}{9}{Gaussian distribution, differences in scale and location. DO assumes location 0, scale 1; DM assumes location 0.18 (bigger than DO), scale 2.7 (broader than DO).\flabel {subfig:GaussLocScale}\relax }{figure.caption.11}{}}
\newlabel{fig:subfig:PW_TK}{{5d}{9}{The observations by \cite {TverskyKahneman1992} are consistent with a DM assuming a scale and location in real-world decisions that differ from those assumed by the DO.\flabel {subfig:PW_TK}\relax }{figure.caption.11}{}}
\newlabel{sub@fig:subfig:PW_TK}{{d}{9}{The observations by \cite {TverskyKahneman1992} are consistent with a DM assuming a scale and location in real-world decisions that differ from those assumed by the DO.\flabel {subfig:PW_TK}\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces {\bf  Effects of differences in location and scale for the decision weight CDFs used by a DM vs. probability CDFs used by a DO.}  {\it  ***MK: Some more summarising text? MK***}  {\it  ***MK: Double check parameter values with py source code MK***} \relax }}{9}{figure.caption.11}}
\newlabel{fig:CDF_weights}{{5}{9}{{\bf Effects of differences in location and scale for the decision weight CDFs used by a DM vs. probability CDFs used by a DO.}\\ \MK {Some more summarising text?} \flabel {CDF_weights} \MK {Double check parameter values with py source code} \relax }{figure.caption.11}{}}
\citation{TverskyKahneman1992}
\citation{TverskyFox1995}
\citation{LattimoreBakerWitte1992}
\citation{tversky1995risk}
\citation{TverskyKahneman1992}
\citation{TverskyFox1995}
\citation{LattimoreBakerWitte1992}
\citation{LattimoreBakerWitte1992}
\citation{TverskyKahneman1992}
\citation{NelderMead1965}
\citation{TverskyKahneman1992}
\citation{TverskyFox1995}
\citation{LattimoreBakerWitte1992}
\citation{LattimoreBakerWitte1992}
\citation{TverskyKahneman1992}
\citation{NelderMead1965}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Probability weighting for Student's-t distributions, where the DM uses a different shape parameter (1) and a different location parameter (0) from those of the DO (2 and 0.2, respectively).\relax }}{10}{figure.caption.12}}
\newlabel{fig:fat_tailed_CDF}{{6}{10}{Probability weighting for Student's-t distributions, where the DM uses a different shape parameter (1) and a different location parameter (0) from those of the DO (2 and 0.2, respectively).\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Fitting the model to experimental results}{10}{section.5}}
\newlabel{eq:LattimoreFunction}{{9}{10}{Fitting the model to experimental results}{equation.5.9}{}}
\bibstyle{apalike}
\bibdata{./../LML_bibliography/bibliography}
\bibcite{AbdellaouiETAL2011}{{1}{2011}{{Abdellaoui et~al.}}{{}}}
\bibcite{Barberis2013}{{2}{2013}{{Barberis}}{{}}}
\bibcite{DeGiorgi2006}{{3}{2006}{{De~Giorgi and Hens}}{{}}}
\bibcite{GonzalezWu1999}{{4}{1999}{{Gonzalez and Wu}}{{}}}
\bibcite{LattimoreBakerWitte1992}{{5}{1992}{{Lattimore et~al.}}{{}}}
\bibcite{NelderMead1965}{{6}{1965}{{Nelder and Mead}}{{}}}
\bibcite{Peters2019b}{{7}{2019}{{Peters}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Model fitting to experimental data from \cite  {TverskyKahneman1992} (left) and \cite  {TverskyFox1995} (right). Left) Gaussian model: $\mu =0.4\tmspace  +\thinmuskip {.1667em}\left (SE = 0.13\right )$, $\sigma =1.5\tmspace  +\thinmuskip {.1667em}\left (\pm 0.2\right )$; Student's-t model: $\nu =0.39\tmspace  +\thinmuskip {.1667em}\left (\pm 0.06\right )$, $\delta =0.29\tmspace  +\thinmuskip {.1667em}\left (\pm 0.08\right )$; \cite  {LattimoreBakerWitte1992}: $\delta =0.67\tmspace  +\thinmuskip {.1667em}\left (\pm 0.07\right )$, $\gamma =0.59\tmspace  +\thinmuskip {.1667em}\left (\pm 0.06\right )$. Right) Gaussian model: $\mu =0.23\tmspace  +\thinmuskip {.1667em}\left (\pm 0.03\right )$, $\sigma =1.4\tmspace  +\thinmuskip {.1667em}\left (\pm 0.06\right )$; Student's-t model: $\nu =0.47\tmspace  +\thinmuskip {.1667em}\left (\pm 0.05\right )$, $\delta =0.17\tmspace  +\thinmuskip {.1667em}\left (\pm 0.03\right )$; \cite  {LattimoreBakerWitte1992}: $\delta =0.77\tmspace  +\thinmuskip {.1667em}\left (\pm 0.02\right )$, $\gamma =0.69\tmspace  +\thinmuskip {.1667em}\left (\pm 0.02\right )$. Shaded areas (noticeable only in the case of \cite  {TverskyKahneman1992}) indicate one standard error in the fitted parameter values. The fit was done by implementing the method of least squares with the Nelder-Mead algorithm \cite  {NelderMead1965}, and the standard errors were obtained by bootstrapping.\relax }}{11}{figure.caption.13}}
\newlabel{fig:TK_TF_fit}{{7}{11}{Model fitting to experimental data from \cite {TverskyKahneman1992} (left) and \cite {TverskyFox1995} (right). Left) Gaussian model: $\mu =0.4\,\left (SE = 0.13\right )$, $\sigma =1.5\,\left (\pm 0.2\right )$; Student's-t model: $\nu =0.39\,\left (\pm 0.06\right )$, $\delta =0.29\,\left (\pm 0.08\right )$; \cite {LattimoreBakerWitte1992}: $\delta =0.67\,\left (\pm 0.07\right )$, $\gamma =0.59\,\left (\pm 0.06\right )$. Right) Gaussian model: $\mu =0.23\,\left (\pm 0.03\right )$, $\sigma =1.4\,\left (\pm 0.06\right )$; Student's-t model: $\nu =0.47\,\left (\pm 0.05\right )$, $\delta =0.17\,\left (\pm 0.03\right )$; \cite {LattimoreBakerWitte1992}: $\delta =0.77\,\left (\pm 0.02\right )$, $\gamma =0.69\,\left (\pm 0.02\right )$. Shaded areas (noticeable only in the case of \cite {TverskyKahneman1992}) indicate one standard error in the fitted parameter values. The fit was done by implementing the method of least squares with the Nelder-Mead algorithm \cite {NelderMead1965}, and the standard errors were obtained by bootstrapping.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion/Summary}{11}{section.6}}
\bibcite{PetersAdamou2015a}{{8}{2018}{{Peters and Adamou}}{{}}}
\bibcite{Prelec1998}{{9}{1998}{{Prelec}}{{}}}
\bibcite{Stott2006}{{10}{2006}{{Stott}}{{}}}
\bibcite{TverskyFox1995}{{11}{1995}{{Tversky and Fox}}{{}}}
\bibcite{TverskyKahneman1992}{{12}{1992}{{Tversky and Kahneman}}{{}}}
\bibcite{tversky1995risk}{{13}{1995}{{Tversky and Wakker}}{{}}}
\bibcite{Wakker2010}{{14}{2010}{{Wakker}}{{}}}
\bibcite{WuGonzalez1996}{{15}{1996}{{Wu and Gonzalez}}{{}}}
